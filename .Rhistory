skip()
pack_course()
?mutate
library(dlpyr)
library(dplyr)
?mutate
library(swirl)
install_course()
swirl("Decision Trees")
bye()
?attr
jjhfwjhf
library(swirl)
install_course()
swirl("Decision Trees")
skip()
skip()
skip()
str(bank_train)
skip()
skip()
play()
?rpart.control
nxt()
skip()
skip()
skip()
skip()
skip()
skip()
skip()
skip()
skip()
skip()
skip()
skip()
skip()
skip()
skip()
skip()
skip()
skip()
library(swirlify)
set_lesson()
pack_course()
library(swirl)
install_course()
swirl("PGDDA Statistics - Descriptive")
8
library(titanic)
str(titanic_train)
t()
nxt()
skip()
skip()
skip()
skip()
skip()
skip()
skip()
skip()
skip()
skip()
skip()
skip()
skip()
skip()
skip()
skip()
skip()
skip()
skip()
skip()
skip()
skip()
xt()
nxt()
swirl()
3
skip()
skip()
unique(day)
skip()
skip()
skip()
skip()
skip()
skip()
skip()
skip()
skip()
skip()
skip()
skip()
skip()
skip()
skip()
skip()
str(iris)
str(iris, echo = F)
str(iris, echo = F)
install.packages("sqldf")
library(swirl)
library(swirlify)
set_lesson()
test_lesson()
demo_lesson()
bye
bye()
demo_lesson()
library(stringr)
str(bm)
bye()
pack_course()
install_course()
swirl("working with strings in R")
2
library(stringr)
str(bm)
bye
bye()
bm <- read.csv(file.path(.get_course_path(),
"stringr", "working_with_strings_in_R", "bank-marketing.csv"))
.get_course_path <- function(){
tryCatch(swirl:::swirl_courses_dir(),
error = function(c) {file.path(find.package("swirl"),"Courses")}
)
}
bm <- read.csv(file.path(.get_course_path(),
"stringr", "working_with_strings_in_R", "bank-marketing.csv"))
bm <- read.csv(file.path(.get_course_path(),
"working_with_strings_in_R", "stringr", "bank-marketing.csv"))
pack_course()
install_course()
install_course()
swirl()
2
library(stringr)
str(bm)
str_count(bm$job, pattern ="tech")
play()
n_tech <- str_count(bm$job, pattern = "tech")
n_tech
n_tech <- sum(str_count(bm$job, pattern = "tech"))
n_tech
nxt()
str_count(bm$job, pattern = 're')
str_count(bm$job, pattern ="re")
str_count(bm$job, pattern = [aeiou])
str_count(bm$job, pattern = "[aeiou]")
play()
?str_count()
nxt()
str_count(bm$job, pattern = "re")
str_detect(bm$job, pattern = "re")
play()
str_count("qbfqwknq;wnk;nqafasmv", pattern = "[aeiou]")
str_count("aeht", pattern = "[aeiou]")
str_count("aehtio", pattern = "[aeiou]")
str_detect("aerr", pattern = "ae")
str_detect("aerr", pattern = "[aeiou")
str_detect("aerr", pattern = "[aeiou]")
str_detect("thgftrr", pattern = "[aeiou]")
str_detect("thgftrra", pattern = "[aeiou]")
str_count(head(bm$job), pattern = "[aeiou]")
?str_count()
str_count("pre-requisities", pattern = "re")
str_count("Keep calm and code", pattern = "[aeiou]")
str_count("paragraph", pattern = "[rap]")
str_detect("vowel", pattern = "[aeiou]")
str_detect("123", pattern = "[a-z")
str_detect("123", pattern = "[a-z]")
str_detect("123abc", pattern = "[a-z]")
str_detect("123abc", pattern = "[1-9]")
str_detect("123abc", pattern = "[0-9]")
str_detect("abc", pattern = "[0-9]")
str_count("abc", pattern = "[0-9]")
str_count("abc2312", pattern = "[0-9]")
str_count("Catch!", pattern = "[a-z]")
str_count("Catch!", pattern = "[A-z]")
str_count("My phone number is 99887766", pattern = "[0-9]")
9988776600
str_count("My phone number is 99887766", pattern = "[0-9]{1-3}")
?str_extract
str_extract(shopping_list, "[a-z]{1,4}")
str_extract("shopping_list", "[a-z]{1,4}")
str_extract("My phone number is 99887766", pattern = "[0-9]{1-3}")
str_extract("My phone number is 99887766", pattern = "[0-9]{1,3}")
str_count("1ab23 alpha", pattern = "[A-z]{1, 5}")
str_extract("ab00c alpha", pattern = "[A-z]{1, 5}")
str_extract("ab00c alpha",  "[A-z]{1,5}")
?str_extract
str_extract("ab00c alpha",  "[A-z]{1,5}")
str_extract("ab00c alpha",  "[A-z]{1,2}")
str_extract("ab00c alpha",  "[A-z]{1,3}")
str_extract("abcdf45 alpha",  "[A-z]{1,3}")
str_extract("abcdf45 alpha",  "[A-z]{1,4}")
str_extract("abcdf45 alpha",  "[A-z]{1,7}")
str_extract("abcdf45alpha",  "[A-z]{1,7}")
str_extract("abcdf45alpha",  "[A-z]{1,7}")
str_extract("abcd00",  "[A-z]{1,5}")
str_extract("abcd00",  pattern = "[A-z]{1,5}")
View(bm)
str_extract("abcd00",  pattern = "[a-z]{1,4}")
str_extract(bm$job,  pattern = "[a-z]{1,4}")
str_extract(bm$job,  pattern = "[a-z]{1,5}")
df <- str_extract(bm$job, "[a-z]{1,4}")
?str_extract_all
df1<- str_extract_all(bm$job, "[a-z]{1,4}")
df1
str_extract(bm$job, pattern = "[a-z]{1,4}")
str_extract_all("abcd00",  pattern = "[a-z]{1,4}")
str_extract_all("abcd00asd",  pattern = "[a-z]{1,7}")
str_extract("abcd00asd",  pattern = "[a-z]{1,7}")
str_extract("91-999000555", pattern = [0-9]{1,10})
str_extract("91-999000555", pattern = "[0-9]{1,10}")
str_extract("91-999000555", pattern = "[0-9]{1,10}")
str_extract("91-999000555", pattern = "[0-9]{10}")
str_extract_all("91-999000555", pattern = "[0-9]{1,10}")
str_extract_all("91-999000555", pattern = "[0-9]{1,4}")
str_extract_all("91-999000555", pattern = "[0-9]{1,2}")
str_extract_all("91-999000555", pattern = "[0-9]{1,3}")
str_extract("91-999-000-555", pattern = "[0-9]{1,10}")
str_extract_all("91-999-000-555", pattern = "[0-9]{1,10}")
str_extract_all("91-999-000-555", pattern = "[0-9]{1,10}")
str_extract_all("91-999-000-555", pattern = "[0-9]{1,3}")
str_extract_all("91-999-000-555", pattern = "[0-9]{1,10}")
str_extract_all("91-999-000-555", pattern = "[0-9]{1,2}")
str_extract_all("91-999-000-555", pattern = "[0-9]{1,10}")
str_extract_all(bm$job, "[a-z]{1,4}")
str_pad(bm$job, width =  15, side = "right", pad ="x")
str_trunc(bm$job, width = 5, side = "right", ellipsis = ".")
str_split(bm$job, pattern = "n")
str_split(ponpo, pattern = "n")
str_split("ponpo", pattern = "n")
str_split("ponpor", pattern = "n")
str_split("my-name-is-khan", pattern = "-")
str_split("my-name-is-khan", pattern = "[aeiou]")
str_split("12erte1212najndjq2313", pattern = "[aeiou]")
str_split("12erte1212najndjq2313", pattern = "[0-9]")
str_split("ab9cd", pattern = "[0-9]")
"022-23455"
str_split("022-23455", "-")
str_split("ab9cd78bshbd876", pattern = "[0-9]")
str_split("mdhwhofeifjcqwhdpih", pattern = "[aeiou]")
nxt()
bye()
demo_lesson()
demo_lesson()
library(swirl)
library(swirlify)
set_lesson()
demo_lesson()
3
library(stringr)
str(bm)
str_count("pre-requisites", pattern = "re")
str_count("pre-requisities", pattern = "re")
str_count(bm$job, pattern= "tech")
n_tech <- sum(str_count(bm$job, pattern= "tech"))
n_re <- sum(str_count(bm$job, pattern= "re"))
str_count( "Keep calm and code", pattern = "[aeiou]")
n_vowels <- str_count( bm$job, pattern = "[aeiou]")
n_vowels <- sum(str_count( bm$job, pattern = "[aeiou]"))
str_detect( "vowel", pattern = "[aeiou]")
str_count("Catch", pattern = "[a-z]")
skip()
skip()
skip()
skip()
skip()
skip()
skip()
skip()
pack_course()
setwd("C:/Users/Pratika/Downloads")
library(tidyr)
library(dplyr)
unicef <- read.csv("unicef.csv")
str(unicef)
unicef_long <- gather(unicef, year, mort_rate, U5MR.1950:U5MR.2015)
str(unicef_long)
View(unicef_long)
library(stringr)
str_replace("MORT4543", "MORT", "")
unicef_long$year <- str_replace(unicef_long$year, "U5MR.", "")
str(unicef_long)
?as.Date
as.Date(unicef_long$year, "%Y")
as.integer(unicef_long$year, "%Y")
unicef_long$year <-  as.integer(unicef_long$year)
str(unicef_long)
str(unicef_long)
filter(unicef_long, CountryName = "Austria", year >= 1970 & year <= 1980)
filter(unicef_long, CountryName == "Austria", year >= 1970 & year <= 1980)
austria70to80 <- filter(unicef_long, CountryName == "Austria", year >= 1970 & year <= 1980)
sum(austria70to80$mort_rate)
mean(austria70to80$mort_rate)
library(sqldf)
India90 <- filter(unicef_long, CountryName == "India", year >= 1981 & year <= 1990)
India90
India20 <- filter(unicef_long, CountryName == "India", year >= 1991 & year <= 2000)
India20
avg90 <- mean(India90$mort_rate)
avg20 <- mean(India20$mort_rate)
avg90
avg20
avg90-avg20
View(unicef)
View(unicef_long)
?aggregate
avg90-avg20
mean(austria70to80$mort_rate)
?group_by
filter(unicef_long, year>=2000 & year<=2015 )
m2015 <- filter(unicef_long, year>=2000 & year<=2015 )
India20
by_country <- group_by(m2015, CountryName)
by_country
summarise(by_country, mean(mort_rate))
m2015 <- filter(unicef_long, year>=2000 & year<=2015 )
by_country <- group_by(m2015, CountryName)
by_country
summarise(by_country, mean(mort_rate))
arrange(s, desc(mort_rate))
s <- summarise(by_country, mean(mort_rate))
arrange(s, desc(mort_rate))
s
arrange(s, desc(mean(mort_rate)))
s <- summarise(by_country, mmr=mean(mort_rate))
s
arrange(s, desc(mmr))
str(m2015)
aggregate(mort_rate~CountryName, data=m2015, mean)
mean_mort_rate <- aggregate(mort_rate~CountryName, data=m2015, mean)
str(mean_mort_rate)
arrange(mean_mort_rate, desc(most_rate))
arrange(mean_mort_rate, desc(mort_rate))
head(arrange(mean_mort_rate, desc(mort_rate)))
Ind <- filter(unicef_long, CountryName=="India")
str(Ind)
head(Ind)
head(Ind)
max_ind <- which(Ind$mort_rate==max(Ind$mort_rate))
Ind[max_ind, ]
max(Ind$mort_rate)
max_ind <- which(Ind$mort_rate==max(Ind$mort_rate, na.rm=T))
Ind[max_ind, ]
min_ind <- which(Ind$mort_rate==min(Ind$mort_rate, na.rm=T))
Ind[min_ind, ]
Ind[max_ind, ]
install.packages("psyche")
install.packages("psych")
library(psych)
Harman74.cor
Thurstone.33
str(Thurstone.33)
t <- as.matrix(Thurstone.33)
t
dim(t)
View(t)
cor.plot(master_pca)
str(master_pca)
master_pca <- master[, -53]
setwd("C:/Users/Pratika/Desktop/Healthcare-Capstone-CMS")
library(dplyr)
library(ggplot2)
library(rpart)
library(randomForest)
library(rpart.plot)
library(RColorBrewer)
library(rattle)
library(caret)
# reading the data from 7 different files each corresponding to a group
effectiveness <- read.csv("effectiveness.csv")
experience <- read.csv("experience.csv")
medical <- read.csv("medical.csv")
mortality <- read.csv("mortality.csv")
readmission <- read.csv("readmission.csv")
safety <- read.csv("safety.csv")
timely <- read.csv("timely.csv")
# CMS ratings data
rating <- read.csv("rating.csv")
# Merging the ratings with the 7 dfs
effectiveness <- merge(effectiveness, rating, by="Provider.ID")
effectiveness <- effectiveness[, -which(names(effectiveness) %in% c("X.x","X.y"))]
experience <- merge(experience, rating, by="Provider.ID")
experience <- experience[, -which(names(experience) %in% c("X.x","X.y"))]
medical <-  merge(medical, rating, by="Provider.ID")
medical <- medical[, -which(names(medical) %in% c("X.x","X.y","X", "Hospital.overall.rating.x"))]
mortality <- merge(mortality, rating, by="Provider.ID")
mortality <- mortality[, -which(names(mortality) %in% c("X.x","X.y"))]
readmission <- merge(readmission, rating, by="Provider.ID")
readmission <- readmission[, -which(names(readmission) %in% c("X.x","X.y"))]
safety <- merge(safety, rating, by="Provider.ID")
safety <- safety[, -which(names(safety) %in% c("X.x","X.y"))]
timely <- merge(timely, rating, by="Provider.ID")
timely <- timely[, -which(names(timely) %in% c("X.x","X.y"))]
# Viewing the structure of the 7 data frames
str(effectiveness)
str(experience)
str(medical)
str(mortality)
str(readmission)
str(safety)
str(timely)
# Basic EDA for each group
# effectiveness
# Merging all dfs together
master <- merge(effectiveness, experience, by="Provider.ID" )
master <- merge(master, medical, by="Provider.ID" )
master <- merge(master, mortality, by="Provider.ID" )
master <- merge(master, readmission, by="Provider.ID" )
master <- merge(master, safety, by="Provider.ID" )
master <- merge(master, timely, by="Provider.ID" )
master <- master[, -which(names(master) %in%
c("Hospital.overall.rating.x", " Hospital.overall.rating.y.x",
"Hospital.overall.rating.y.y", "Hospital.overall.rating.y"))]
str(master)
summary(master$Hospital.overall.rating)
#removing the entries where rating is NA
master <- master[-which(master$Hospital.overall.rating == "Not Available"), ]
# removing the factor level 'Not Available'
master$Hospital.overall.rating <- as.factor(as.integer(master$Hospital.overall.rating))
summary(master$Hospital.overall.rating)
nrow(master)
# splitting the data
str(master)
master <- master[ , -1]
na_cols <- sapply(master, function(x) sum(is.na(x)))
na_cols
na_cols <- names(na_cols)[which(na_cols>1800)]
na_cols
# removing columns having more than 1800 NA values
master <- master[, -which(names(master) %in% na_cols)]
str(master)
n <- nrow(master)
s <- sample(1:n, size=0.8*n)
train <- master[s, ]
test <- master[-s, ]
summary(train$Hospital.overall.rating)
summary(test$Hospital.overall.rating)
# tree
tree <- rpart(Hospital.overall.rating ~., data=train, na.action=na.omit,
control = rpart.control(minsplit=15, cp=0.01))
plot(tree)
fancyRpartPlot(tree)
summary(tree)
#Predictions
tree_pred <-  predict(tree, test[, -53], type = "class")
table(tree_pred, test[, 53])
confusionMatrix(tree_pred, test[, 53])
# Trying collapsing ratings into (1,2=low), (3=avg), (4,5) = good
summary(master$Hospital.overall.rating)
for (row in 1:nrow(master)){
if (master$Hospital.overall.rating[row] == 2){
master$Hospital.overall.rating[row] = 1
}
if (master$Hospital.overall.rating[row] == 4){
master$Hospital.overall.rating[row] = 5
}
}
master$Hospital.overall.rating <- as.integer(master$Hospital.overall.rating)
master$Hospital.overall.rating <- as.factor(master$Hospital.overall.rating)
summary(master$Hospital.overall.rating)
# Building the tree again
n <- nrow(master)
s <- sample(1:n, size=0.8*n)
train <- master[s, ]
test <- master[-s, ]
summary(train$Hospital.overall.rating)
summary(test$Hospital.overall.rating)
tree <- rpart(Hospital.overall.rating ~., data=train, na.action=na.omit,
control = rpart.control(minsplit=50, cp=0.01))
fancyRpartPlot(tree)
tree$cptable
summary(tree)
#Predictions
tree_pred <-  predict(tree, test[, -53], type = "class")
table(tree_pred, test[, 53])
confusionMatrix(tree_pred, test[, 53])
#tree with reduced minsplit of 10 and cp=0.01
tree <- rpart(Hospital.overall.rating ~., data=train, na.action=na.omit,
control = rpart.control(minsplit=10, cp=0.01))
fancyRpartPlot(tree)
tree_pred <-  predict(tree, test[, -53], type = "class")
table(tree_pred, test[, 53])
confusionMatrix(tree_pred, test[, 53])
#rf
summary(train$Hospital.overall.rating)
summary(test$Hospital.overall.rating)
rf <- randomForest(Hospital.overall.rating ~., data=train, mtry=20, na.action=na.omit, ntree=800)
rf
#predict using rf
rf_pred <- predict(rf, newdata=test[, -53])
table(rf_pred, test[, 53])
confusionMatrix(rf_pred, test[, 53])
# random forest performs much better than the tree
# trying to increase the number of trees to 1200
rf <- randomForest(Hospital.overall.rating ~., data=train, mtry=20, na.action=na.omit, ntree=1200)
rf
rf_pred <- predict(rf, newdata=test[, -53])
table(rf_pred, test[, 53])
confusionMatrix(rf_pred, test[, 53])
imp <- rf$importance
master_pca <- master[, -53]
master_pca <- data.frame(scale(master_pca))
str(master_pca)
cor.plot(master_pca)
str(effectiveness)
cor.plot(effectiveness)
cor.plot(effectiveness[, -c(1, 20)])
